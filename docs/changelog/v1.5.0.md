## [1.5.0] - 2025-01-10

### Added
- **FLUX Kontext LoRA Training Support**: Complete implementation of LoRA fine-tuning functionality for FLUX Kontext models
  - 支持三种精度级别：FP16（最高质量）、FP8（平衡性能）、FP4（最大效率）
  - 提供预配置的训练配置文件：`face_seg_flux_kontext_fp16.yaml`、`face_seg_flux_kontext_fp8.yaml`、`face_seg_flux_kontext_fp4.yaml`
  - 实现了 `FluxKontextLoraTrainer` 类，继承自 `BaseTrainer` 确保接口一致性
  - 支持双文本编码器架构（CLIP + T5），优化多设备分配策略
  - 完整的缓存系统支持，包括 VAE、CLIP 和 T5 编码器的独立设备配置

### Changed
- **Documentation Enhancement**: Added detailed FLUX Kontext training guidance section in `docs/training.md`
  - 详细的精度对比表格，包含质量、训练速度、显存需求和使用场景
  - 完整的训练工作流程和多GPU训练配置
  - 设备分配策略和内存优化建议
  - FLUX Kontext 推理代码示例和最佳实践
- **框架描述更新**: 更新 README.md 以反映双模型架构支持
  - 强调对 Qwen-Image-Edit 和 FLUX Kontext 的完整支持
  - 突出多精度训练能力（FP16/FP8/FP4）
  - 更新技术支持部分，添加 FLUX Kontext 训练指南链接

### Technical Details
- FLUX Kontext model architecture: Transformer-based diffusion model supporting joint understanding of images and text
- Precision performance comparison: FP16 (reference quality), FP8 (95% quality, 1.5x speed), FP4 (85% quality, 2.5x speed)
- Memory requirement optimization: FP16 (24GB training/12GB inference) → FP8 (18GB/8GB) → FP4 (12GB/5GB)
- 支持的预训练模型：
  - `black-forest-labs/FLUX.1-Kontext-dev` (FP16)
  - `camenduru/flux1-kontext-dev_fp8_e4m3fn_diffusers` (FP8)
  - `eramth/flux-kontext-4bit-fp4` (FP4)

---
