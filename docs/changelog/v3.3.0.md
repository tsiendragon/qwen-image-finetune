# v3.3.0 Release Notes

## Overview

Version 3.3.0 introduces full support for DreamOmni2 LoRA fine-tuning, extending the framework to support multi-image conditioning with cumulative offset positioning. This enables training models that can handle multiple reference images simultaneously with proper spatial relationship encoding.

## New Features

### DreamOmni2 Trainer Support

- **New Trainer Class**: `DreamOmni2Trainer` extends `FluxKontextLoraTrainer` with DreamOmni2-specific features
- **Cumulative Offset Support**: Implements cumulative offset calculation for multi-image position encoding, ensuring RoPE (Rotary Position Embedding) correctly understands spatial relationships between multiple images
- **VLM Prompt Optimization**: Optional VLM-based prompt enhancement using Qwen2.5-VL model for better instruction understanding
- **Multi-Image Handling**: Supports training with multiple reference images using cumulative column offsets (`w_offset`, `h_offset`)

#### Key Technical Innovation

The core difference from Flux Kontext trainer is the cumulative offset mechanism:

**Flux Kontext Trainer**:
- Multiple control images, each starting from column 0
- Image 1: `col=[0..W1-1]`
- Image 2: `col=[0..W2-1]` ⚠️ Overlapping coordinates

**DreamOmni2 Trainer**:
- Cumulative offsets ensure continuous column coordinates
- Image 1: `col=[0..W1-1]`
- Image 2: `col=[W1..W1+W2-1]` ✅ Continuous coordinates
- This allows RoPE to correctly understand spatial relationships

#### Configuration

```yaml
trainer: DreamOmni2

model:
  pretrained_model_name_or_path: "black-forest-labs/FLUX.1-Kontext-dev"
  use_vlm_prompt_enhancer: true  # Enable VLM prompt enhancement
  lora:
    r: 16
    lora_alpha: 16
    target_modules: ["to_k", "to_q", "to_v", "to_out.0"]

cache:
  devices:
    prompt_enhancer: "cuda:2"  # VLM model device during cache stage

predict:
  devices:
    prompt_enhancer: "cuda:2"  # VLM model device during predict stage
```

#### VLM Prompt Optimization

The trainer supports optional VLM-based prompt optimization using the Qwen2.5-VL model:

- **Automatic Prompt Enhancement**: Uses VLM to understand images and improve instruction prompts
- **Configurable Device Placement**: VLM model can be placed on different GPUs during cache/predict stages
- **Smart Resource Management**: Automatically manages VLM model loading based on training stage (cache vs fit vs predict)

## Technical Implementation

### Core Components

- **DreamOmni2Trainer**: New trainer class inheriting from `FluxKontextLoraTrainer`
- **Pipeline Integration**: Uses `DreamOmni2Pipeline` for inference and LoRA weight saving
- **Cumulative Offset Calculation**: Applied in `prepare_embeddings()` before concatenating control latents
- **VLM Integration**: Optional Qwen2.5-VL model for prompt optimization

### Key Methods

1. **prepare_embeddings()**: Overrides parent method to add:
   - VLM prompt optimization (optional)
   - Cumulative offset calculation for multi-image positioning

2. **optimize_prompt_with_vlm()**: Uses VLM to enhance prompts based on input images

3. **load_vlm_model()**: Loads Qwen2.5-VL model for prompt optimization

### Architecture Compatibility

DreamOmni2 trainer uses the same core components as Flux Kontext:
- **Transformer**: `FluxTransformer2DModel`
- **VAE**: `AutoencoderKL`
- **Text Encoders**: CLIP and T5
- **Scheduler**: `FlowMatchEulerDiscreteScheduler`

The main difference is the cumulative offset mechanism for multi-image handling.

## Migration Guide

### For New Users

To use DreamOmni2 trainer, simply set `trainer: DreamOmni2` in your config file and follow the example configuration above.

### For Existing Flux Kontext Users

DreamOmni2 trainer is compatible with existing Flux Kontext configurations. The key differences:
- Uses cumulative offsets for multi-image support (algorithmic improvement)
- Adds optional VLM prompt optimization feature
- Otherwise maintains full compatibility with Flux Kontext training pipeline

## Dependencies

No new dependencies required. DreamOmni2 trainer uses existing dependencies:
- `diffusers`: For DreamOmni2Pipeline
- `transformers`: For VLM model (only if `use_vlm_prompt_enhancer: true`)

## Testing

- Unit tests for DreamOmni2 trainer
- Integration tests with multi-image datasets
- VLM prompt optimization verified
- Cumulative offset calculation verified
- Example config: `tests/test_configs/test_dreamomni2_fp16.yaml`

## Related Documentation

- Implementation Plan: `docs/plan/dreamomni2_trainer_plan.md`
- DreamOmni2 Reading Notes: `docs/references/dreamomni2_reading_notes.md`
- Example Configuration: `tests/test_configs/test_dreamomni2_fp16.yaml`

## Breaking Changes

None. This is a backwards-compatible addition (MINOR version bump).

## Future Enhancements

- Enhanced multi-image composition capabilities
- Additional VLM models for prompt optimization
- Advanced multi-resolution support for DreamOmni2
