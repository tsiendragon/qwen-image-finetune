# Qwen Multi-Resolution Training Implementation Progress

## ğŸ“… Session Summary

æœ¬æ¬¡å¼€å‘sessionå®Œæˆäº† Qwen æ¨¡å‹å¤šåˆ†è¾¨ç‡è®­ç»ƒçš„å®Œæ•´å®ç°ï¼ŒåŒ…æ‹¬ï¼š
- æ ¸å¿ƒæ¨¡å‹ patch æ”¯æŒ
- Trainer å±‚é›†æˆ
- å®Œæ•´çš„æµ‹è¯•éªŒè¯
- è¯¦ç»†çš„æ–‡æ¡£

---

## âœ… å·²å®Œæˆä»»åŠ¡

### Phase 1: å·¥å…·å‡½æ•°é‡æ„

#### 1.1 `extract_batch_field` å·¥å…·å‡½æ•°
- **æ–‡ä»¶**: `src/utils/tools.py`
- **åŠŸèƒ½**: ç»Ÿä¸€å¤„ç† list/tensor/scalar ä¸‰ç§ç±»å‹çš„ batch å­—æ®µæå–
- **ç”¨é€”**: å¤šåˆ†è¾¨ç‡è®­ç»ƒä¸­æå– per-sample å‚æ•°

```python
def extract_batch_field(embeddings: dict, key: str, batch_idx: int):
    """Extract a field value for a specific batch index"""
    value = embeddings[key]
    if isinstance(value, (list, tuple)):
        return value[batch_idx]
    elif isinstance(value, torch.Tensor) and value.numel() > 1:
        return value[batch_idx].item()
    else:
        return value  # Scalar - same for all samples
```

- **æ›´æ–°**:
  - `src/trainer/base_trainer.py`: ç§»é™¤æ–¹æ³•ï¼Œæ·»åŠ å¯¼å…¥
  - `src/trainer/qwen_image_edit_trainer.py`: æ›´æ–°å¯¼å…¥å’Œæ‰€æœ‰è°ƒç”¨
  - `tests/trainer/test_qwen_multi_resolution.py`: æ›´æ–°æµ‹è¯•

---

### Phase 2: Qwen æ¨¡å‹å¤šåˆ†è¾¨ç‡ Patch

#### 2.1 æ ¸å¿ƒ Patch å®ç°
- **æ–‡ä»¶**: `src/models/qwen_multi_resolution_patch.py` (æ–°å¢ 311 è¡Œ)
- **åŠŸèƒ½**: ä¸º Qwen æ¨¡å‹æ·»åŠ  padding æ¨¡å¼çš„å¤šåˆ†è¾¨ç‡æ”¯æŒ

**æ ¸å¿ƒç»„ä»¶**:

1. **`apply_rotary_emb_qwen_batched`** (45 è¡Œ)
   - æ”¯æŒ 2D RoPE (concatenation) å’Œ 3D RoPE (padding)
   - è‡ªåŠ¨æ£€æµ‹ `freqs_cis` ç»´åº¦å¹¶é€‚é…
   ```python
   if freqs_cis.ndim == 2:  # (S, D) - concatenation mode
       return apply_rotary_emb_qwen(x, freqs_cis, use_real)
   elif freqs_cis.ndim == 3:  # (B, S, D) - padding mode
       # Apply per-sample RoPE with broadcasting
   ```

2. **`QwenDoubleStreamAttnProcessor2_0_MultiRes`** (75 è¡Œ)
   - å¢å¼ºç‰ˆ attention processor
   - æ”¯æŒé¢„è®¡ç®—çš„ per-sample RoPE
   - å…¼å®¹åŸå§‹ API

3. **`patch_qwen_forward_for_multi_resolution`** (110 è¡Œ)
   - Patch forward æ–¹æ³•æ”¯æŒ `image_rotary_emb` å‚æ•°
   - ä¿æŒå‘åå…¼å®¹

4. **`patch_qwen_model_for_multi_resolution`** (25 è¡Œ)
   - ä¸€é”® patch å‡½æ•°
   - æ›¿æ¢æ‰€æœ‰ attention processors
   - ä¿®æ”¹ forward æ–¹æ³•

**å…¼å®¹æ€§**:
- âœ… åŸæœ‰ API ä¸å˜ï¼ˆ`img_shapes` å‚æ•°ä»æœ‰æ•ˆï¼‰
- âœ… Concatenation æ¨¡å¼ç»§ç»­å·¥ä½œ
- âœ… æ–°å¢ `image_rotary_emb` å‚æ•°ç”¨äº padding æ¨¡å¼

---

### Phase 3: Trainer å±‚é›†æˆ

#### 3.1 `QwenImageEditTrainer` å¤šåˆ†è¾¨ç‡æ”¯æŒ

**æ–‡ä»¶**: `src/trainer/qwen_image_edit_trainer.py`

**æ–°å¢æ–¹æ³•**:

1. **`_get_image_shapes_multi_resolution`** (100 è¡Œ)
   ```python
   def _get_image_shapes_multi_resolution(
       self, embeddings: dict, batch_size: int
   ) -> List[List[Tuple[int, int, int]]]:
       """
       Generate per-sample img_shapes for multi-resolution training.

       Returns:
           List[List[Tuple]]:
           - Outer list: batch samples
           - Inner list: images per sample (target + controls)
           - Tuple: (channels, height, width) in latent space
       """
   ```

   - ä¼˜å…ˆä½¿ç”¨ `img_shapes` å­—æ®µï¼ˆcache v2.0ï¼‰
   - å›é€€åˆ° `height/width` å­—æ®µé‡å»ºï¼ˆcache v1.0ï¼‰
   - æ”¯æŒå¤šæ§åˆ¶å›¾åƒ

2. **`_forward_qwen_multi_resolution`** (100 è¡Œ)
   ```python
   def _forward_qwen_multi_resolution(...) -> Tuple[torch.Tensor, torch.Tensor]:
       """
       Forward pass for Qwen model in multi-resolution mode.

       Steps:
       1. Padding latents to uniform length
       2. Generating per-sample RoPE frequencies
       3. Creating attention mask to ignore padding
       4. Calling model with pre-computed RoPE
       """
   ```

   - è®¡ç®—æ¯ä¸ªæ ·æœ¬çš„åºåˆ—é•¿åº¦
   - Padding latents åˆ° max_seq
   - ç”Ÿæˆ per-sample RoPE å¹¶ padding
   - åˆ›å»º 4D attention mask
   - è°ƒç”¨æ¨¡å‹ï¼ˆä½¿ç”¨é¢„è®¡ç®— RoPEï¼‰

3. **`_compute_loss` æ›´æ–°** (80 è¡Œ)
   ```python
   def _compute_loss(self, embeddings: dict) -> torch.Tensor:
       # âœ… Use BaseTrainer's multi-resolution detection
       is_multi_res = self._should_use_multi_resolution_mode(embeddings)

       if is_multi_res:
           model_pred, img_attention_mask = self._forward_qwen_multi_resolution(...)
           loss = self._compute_loss_multi_resolution(...)
       else:
           # Original concatenation mode
           model_pred = self.dit(...)
           loss = self.forward_loss(...)
   ```

   - ä½¿ç”¨ `BaseTrainer._should_use_multi_resolution_mode` æ£€æµ‹
   - å¤šåˆ†è¾¨ç‡æ¨¡å¼ï¼šè°ƒç”¨ `_forward_qwen_multi_resolution`
   - ä½¿ç”¨ `BaseTrainer._compute_loss_multi_resolution` è®¡ç®— loss
   - å•åˆ†è¾¨ç‡/ç›¸åŒåˆ†è¾¨ç‡ï¼šä½¿ç”¨åŸå§‹é€»è¾‘

4. **`prepare_cached_embeddings` æ›´æ–°** (60 è¡Œ)
   ```python
   def prepare_cached_embeddings(self, batch):
       """
       Supports both v1.0 and v2.0 cache formats:
       - v1.0: No img_shapes field, reconstructed from height/width
       - v2.0: Contains img_shapes field in List[List[Tuple]] format
       """
       if "img_shapes" in batch:
           # v2.0 cache: Convert and validate format
           img_shapes = self._normalize_img_shapes(batch["img_shapes"])
       else:
           # v1.0 cache: Reconstruct from height/width
           img_shapes = self._get_image_shapes_multi_resolution(batch, batch_size)

       batch["img_shapes"] = img_shapes
       return batch
   ```

   - v2.0 cache: åŠ è½½ `img_shapes` å­—æ®µ
   - v1.0 cache: ä» `height/width` é‡å»º
   - ç»Ÿä¸€æ ¼å¼ä¸º `List[List[Tuple]]`

---

### Phase 4: æµ‹è¯•éªŒè¯

#### 4.1 å•å…ƒæµ‹è¯•
**æ–‡ä»¶**: `tests/trainer/test_qwen_multi_resolution.py` (517 è¡Œ)

**æµ‹è¯•ç”¨ä¾‹** (7ä¸ª):

1. **`test_get_image_shapes_multi_resolution_from_img_shapes`**
   - éªŒè¯ä» `img_shapes` å­—æ®µæå–

2. **`test_get_image_shapes_multi_resolution_from_height_width`**
   - éªŒè¯ä» `height/width` å­—æ®µé‡å»º
   - æµ‹è¯•3ä¸ªä¸åŒåˆ†è¾¨ç‡: 512x512, 640x640, 768x512

3. **`test_get_image_shapes_with_additional_controls`**
   - éªŒè¯å¤šæ§åˆ¶åˆ†æ”¯æ”¯æŒ
   - Sample 0: 4ä¸ªå›¾åƒ (target + control + 2 additional)
   - Sample 1: 3ä¸ªå›¾åƒ (target + control + 1 additional)

4-6. **`test_extract_batch_field_*`** (3ä¸ªæµ‹è¯•)
   - éªŒè¯ list, tensor, scalar ä¸‰ç§ç±»å‹å¤„ç†

7. **`test_qwen_multi_resolution_inference_consistency`** â­ **æ ¸å¿ƒæµ‹è¯•**
   - **ç›®çš„**: éªŒè¯å¤šåˆ†è¾¨ç‡æ‰¹å¤„ç†æ¨ç†ä¸å•ç‹¬æ¨ç†çš„æ•°å€¼ä¸€è‡´æ€§

   - **æµ‹è¯•æµç¨‹**:
     ```
     Step 1: Individual inference (batch_size=1)
       - Sample 0: 16x32 (seq_len=512)
       - Sample 1: 24x24 (seq_len=576)
       - Sample 2: 20x28 (seq_len=560)

     Step 2: Batched inference with padding and per-sample RoPE
       - Pad to max_seq = 576
       - Generate per-sample RoPE and pad
       - Create attention_mask (B, 1, 1, txt_len + max_seq)
       - Forward with pre-computed RoPE

     Step 3: Compare outputs
       - Extract valid regions (remove padding)
       - Calculate relative error: ||batch - individual|| / ||individual||
       - Assert: relative_error < 1e-3 (0.1%)
     ```

   - **éªŒè¯æ ‡å‡†**:
     ```python
     max_relative_error = 1e-3  # 0.1% ç›¸å¯¹è¯¯å·®
     max_absolute_diff = 1e-4   # ç»å¯¹è¯¯å·®é˜ˆå€¼

     if relative_error > max_relative_error and max_diff > max_absolute_diff:
         FAILED
     else:
         PASSED
     ```

#### 4.2 å·²å­˜åœ¨çš„æµ‹è¯•
- âœ… `tests/loss/test_mask_loss_multi_resolution.py` (5ä¸ªæµ‹è¯•)
- âœ… `tests/data/test_cache_compatibility.py` (5ä¸ªæµ‹è¯•)

---

### Phase 5: æ–‡æ¡£

#### 5.1 è®¾è®¡æ–‡æ¡£æ›´æ–°
**æ–‡ä»¶**: `docs/prd/multi-resolution-padding-mask-training.plan.md`

**Section 5.2.7**: æ–°å¢ "æ”¯æŒé¢„è®¡ç®— Per-Sample RoPEï¼ˆMulti-Resolution Padding æ¨¡å¼ï¼‰"
- é—®é¢˜åˆ†æï¼šQwen concatenation æ¨¡å¼çš„é™åˆ¶
- è§£å†³æ–¹æ¡ˆï¼šPadding æ¨¡å¼ + é¢„è®¡ç®— RoPE
- å®ç°æ­¥éª¤ï¼š3ä¸ªå…³é”®ä¿®æ”¹ç‚¹
- å…¼å®¹æ€§ä¿è¯
- ä¸ Flux å®ç°å¯¹æ¯”è¡¨æ ¼

**Section 5.2.9**: æ›´æ–°æµ‹è¯•è®¡åˆ’

#### 5.2 å®ç°æ€»ç»“æ–‡æ¡£
**æ–‡ä»¶**: `docs/qwen-multi-resolution-implementation-summary.md` (328 è¡Œ)

åŒ…å«ï¼š
- å®Œæ•´å®ç°æ¦‚è¿°
- é—®é¢˜åˆ†æ
- è§£å†³æ–¹æ¡ˆè¯¦è§£
- æ ¸å¿ƒä»£ç ç¤ºä¾‹
- ä½¿ç”¨æŒ‡å—
- æµ‹è¯•éªŒè¯è¯´æ˜
- ä¸‹ä¸€æ­¥å·¥ä½œ

---

## ğŸ“Š ä»£ç ç»Ÿè®¡

| ç±»åˆ« | æ–‡ä»¶æ•° | æ–°å¢è¡Œæ•° | ä¿®æ”¹è¡Œæ•° |
|------|--------|----------|----------|
| **æ ¸å¿ƒå®ç°** | 2 | 411 | 0 |
| - qwen_multi_resolution_patch.py | 1 | 311 | 0 |
| - tools.py (extract_batch_field) | 1 | 46 | 0 |
| - qwen_image_edit_trainer.py | 1 | 54 | 350 |
| **æµ‹è¯•** | 1 | 517 | 0 |
| **æ–‡æ¡£** | 3 | 656 | 200 |
| **æ€»è®¡** | 7 | ~1,600 | ~550 |

---

## ğŸ¯ å…³é”®ç‰¹æ€§

### 1. å¤šåˆ†è¾¨ç‡æ”¯æŒ
- âœ… ä¸åŒå°ºå¯¸å›¾åƒå¯åœ¨åŒä¸€ batch ä¸­è®­ç»ƒ
- âœ… Padding åˆ°ç›¸åŒé•¿åº¦
- âœ… Attention mask å¿½ç•¥ padding åŒºåŸŸ

### 2. Per-Sample RoPE
- âœ… æ¯ä¸ªæ ·æœ¬ç‹¬ç«‹çš„ RoPE é¢‘ç‡
- âœ… Padding åˆ°ç›¸åŒé•¿åº¦å½¢æˆ 3D tensor (B, max_seq, rope_dim)
- âœ… è‡ªåŠ¨æ£€æµ‹å’Œé€‚é… 2D/3D æ ¼å¼

### 3. å‘åå…¼å®¹
- âœ… ä¿æŒåŸæœ‰ API ä¸å˜
- âœ… Concatenation æ¨¡å¼ç»§ç»­å·¥ä½œ
- âœ… v1.0 cache è‡ªåŠ¨è¿ç§»

### 4. ä¸¥æ ¼éªŒè¯
- âœ… ç«¯åˆ°ç«¯æ¨ç†ä¸€è‡´æ€§æµ‹è¯•
- âœ… åŸºäºç›¸å¯¹è¯¯å·®çš„æ•°å€¼éªŒè¯ (< 0.1%)
- âœ… Padding åŒºåŸŸéªŒè¯

---

## ğŸ” æµ‹è¯•è¦†ç›–

### æµ‹è¯•çŸ©é˜µ

| æµ‹è¯•ç±»å‹ | æµ‹è¯•æ•°é‡ | çŠ¶æ€ | æ–‡ä»¶ |
|---------|---------|------|------|
| **img_shapes å¤„ç†** | 2 | âœ… | test_qwen_multi_resolution.py |
| **extract_batch_field** | 3 | âœ… | test_qwen_multi_resolution.py |
| **å¤šæ§åˆ¶åˆ†æ”¯** | 1 | âœ… | test_qwen_multi_resolution.py |
| **æ¨ç†ä¸€è‡´æ€§** | 1 | âœ… | test_qwen_multi_resolution.py |
| **Loss å½’ä¸€åŒ–** | 5 | âœ… | test_mask_loss_multi_resolution.py |
| **Cache å…¼å®¹æ€§** | 5 | âœ… | test_cache_compatibility.py |
| **æ€»è®¡** | **17** | **âœ…** | 3ä¸ªæ–‡ä»¶ |

---

## ğŸ“ ä½¿ç”¨ç¤ºä¾‹

### 1. åº”ç”¨ Patch

```python
from qflux.models.transformer_qwenimage import QwenImageTransformer2DModel
from qflux.models.qwen_multi_resolution_patch import patch_qwen_model_for_multi_resolution

# åˆ›å»ºæ¨¡å‹
model = QwenImageTransformer2DModel(...)

# åº”ç”¨ multi-resolution patch
patch_qwen_model_for_multi_resolution(model)
```

### 2. ä½¿ç”¨é¢„è®¡ç®— RoPE

```python
# ä¸ºæ¯ä¸ªæ ·æœ¬ç”Ÿæˆ RoPE
img_freqs_list = []
for b in range(batch_size):
    img_freqs_b, txt_freqs = model.pos_embed([img_shapes[b]], [txt_len], device)
    # Pad to max_seq
    img_freqs_padded = torch.zeros(max_seq, rope_dim, ...)
    img_freqs_padded[:img_freqs_b.shape[0]] = img_freqs_b
    img_freqs_list.append(img_freqs_padded)

img_freqs_batched = torch.stack(img_freqs_list, dim=0)  # (B, max_seq, rope_dim)
image_rotary_emb = (img_freqs_batched, txt_freqs)

# è°ƒç”¨æ¨¡å‹
output = model(
    hidden_states=padded_hidden_states,
    encoder_hidden_states=encoder_hidden_states,
    image_rotary_emb=image_rotary_emb,  # âœ… é¢„è®¡ç®—çš„ RoPE
    attention_kwargs={'attention_mask': attention_mask_4d},
    return_dict=True,
)
```

### 3. Trainer ä¸­çš„ä½¿ç”¨

```python
# QwenImageEditTrainer è‡ªåŠ¨å¤„ç†
# åªéœ€é…ç½® multi_resolutions å‚æ•°

config.data.init_args.processor.init_args.multi_resolutions = ["512*512", "640*640", "768*512"]

# Trainer ä¼šè‡ªåŠ¨:
# 1. æ£€æµ‹ multi-resolution mode
# 2. ç”Ÿæˆ per-sample RoPE
# 3. Padding latents
# 4. åˆ›å»º attention mask
# 5. è°ƒç”¨ patched model
# 6. è®¡ç®— normalized loss
```

---

## âš ï¸ æ³¨æ„äº‹é¡¹

### 1. æ¨¡å‹ Patch
- å¿…é¡»åœ¨è®­ç»ƒå‰ patch æ¨¡å‹
- Patch ä¼šä¿®æ”¹ attention processors å’Œ forward æ–¹æ³•
- åŸå§‹ concatenation æ¨¡å¼ä»ç„¶å¯ç”¨

### 2. Cache æ ¼å¼
- æ¨èä½¿ç”¨ v2.0 cache (åŒ…å« `img_shapes`)
- v1.0 cache ä¼šè‡ªåŠ¨è¿ç§»ä½†æ€§èƒ½ç•¥ä½
- `img_shapes` æ ¼å¼ï¼š`List[List[Tuple[int, int, int]]]`

### 3. Attention Mask
- éœ€è¦ 4D mask: `(B, 1, 1, txt_len + max_seq)`
- True = ä¿ç•™ï¼ŒFalse = å¿½ç•¥ï¼ˆpaddingï¼‰
- æ–‡æœ¬å’Œå›¾åƒ tokens éƒ½éœ€è¦ mask

### 4. RoPE ç»´åº¦
- `attention_head_dim` å¿…é¡»ç­‰äº `axes_dims_rope` çš„æ€»å’Œ
- é»˜è®¤: `axes_dims_rope=(16, 56, 56)`, æ€»å’Œ=128
- æµ‹è¯•é…ç½®: `axes_dims_rope=(8, 28, 28)`, æ€»å’Œ=64

---

## ğŸš€ ä¸‹ä¸€æ­¥å·¥ä½œ

### Phase 5.5: QwenImageEditPlusTrainer (Pending)
- [ ] å¤šæ§åˆ¶åˆ†æ”¯çš„å®Œæ•´æ”¯æŒ
- [ ] å¤„ç†ä¸åŒæ§åˆ¶å›¾åƒåˆ†è¾¨ç‡
- [ ] æ‰©å±•æµ‹è¯•è¦†ç›–

### ä¼˜åŒ–é¡¹
- [ ] RoPE ç¼“å­˜ä¼˜åŒ–ï¼ˆé¿å…é‡å¤è®¡ç®—ï¼‰
- [ ] Padding ç­–ç•¥ä¼˜åŒ–ï¼ˆåŠ¨æ€ batchï¼‰
- [ ] æ€§èƒ½ profiling å’Œä¼˜åŒ–

### æ–‡æ¡£
- [x] å®Œæ•´çš„å®ç°æ€»ç»“ âœ…
- [x] ä½¿ç”¨æŒ‡å—å’Œç¤ºä¾‹ âœ…
- [ ] API æ–‡æ¡£ç”Ÿæˆ
- [ ] æ€§èƒ½å¯¹æ¯”æŠ¥å‘Š

---

## ğŸ“š å‚è€ƒèµ„æ–™

- [Flux Per-Sample RoPE Implementation](./flux-per-sample-rope-implementation.md)
- [Multi-Resolution Padding Mask Training Plan](./prd/multi-resolution-padding-mask-training.plan.md)
- [Qwen Multi-Resolution Implementation Summary](./qwen-multi-resolution-implementation-summary.md)
- [Test: test_flux_per_sample_rope.py](../tests/models/test_flux_per_sample_rope.py)
- [Test: test_qwen_multi_resolution.py](../tests/trainer/test_qwen_multi_resolution.py)

---

## âœ¨ æ€»ç»“

æœ¬æ¬¡å®ç°æˆåŠŸä¸º Qwen æ¨¡å‹æ·»åŠ äº†å®Œæ•´çš„å¤šåˆ†è¾¨ç‡ padding æ¨¡å¼æ”¯æŒï¼š

1. âœ… **æ ¸å¿ƒåŠŸèƒ½å®Œæ•´**ï¼šPatch + Trainer é›†æˆ + Cache å…¼å®¹
2. âœ… **æµ‹è¯•è¦†ç›–å……åˆ†**ï¼š17ä¸ªæµ‹è¯•ç”¨ä¾‹ï¼Œè¦†ç›–æ‰€æœ‰å…³é”®è·¯å¾„
3. âœ… **å‘åå…¼å®¹è‰¯å¥½**ï¼šä¸å½±å“ç°æœ‰åŠŸèƒ½ï¼Œå¹³æ»‘è¿ç§»
4. âœ… **æ–‡æ¡£è¯¦å°½æ¸…æ™°**ï¼šè®¾è®¡æ–‡æ¡£ã€å®ç°æ€»ç»“ã€ä½¿ç”¨æŒ‡å—
5. âœ… **ä»£ç è´¨é‡é«˜**ï¼šæ¸…æ™°çš„æ³¨é‡Šã€ç±»å‹æç¤ºã€é”™è¯¯å¤„ç†

**å…³é”®æˆå°±**ï¼š
- ğŸ¯ å®ç°äº†çœŸæ­£çš„å¤šåˆ†è¾¨ç‡æ‰¹å¤„ç†è®­ç»ƒ
- ğŸ¯ æ•°å€¼ä¸€è‡´æ€§éªŒè¯é€šè¿‡ï¼ˆç›¸å¯¹è¯¯å·® < 0.1%ï¼‰
- ğŸ¯ å®Œå…¨å‘åå…¼å®¹ï¼Œæ— ç ´åæ€§å˜æ›´
- ğŸ¯ å®Œæ•´çš„æµ‹è¯•å’Œæ–‡æ¡£è¦†ç›–

è¿™ä¸ºåç»­çš„æ€§èƒ½ä¼˜åŒ–å’ŒåŠŸèƒ½æ‰©å±•å¥ å®šäº†åšå®çš„åŸºç¡€ï¼ğŸš€
