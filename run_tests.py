#!/usr/bin/env python3
"""
è¿è¡Œæ¨¡å‹æ¯”è¾ƒæµ‹è¯•çš„è„šæœ¬
"""

import sys
import os
import unittest

# æ·»åŠ é¡¹ç›®æ ¹ç›®å½•åˆ°Pythonè·¯å¾„
sys.path.insert(0, os.path.dirname(__file__))

def run_model_comparison_tests():
    """è¿è¡Œæ¨¡å‹æ¯”è¾ƒæµ‹è¯•"""
    print("ğŸ§ª å¼€å§‹è¿è¡ŒQwen Imageæ¨¡å‹æ¯”è¾ƒæµ‹è¯•...")
    print("="*80)

    # å‘ç°å¹¶è¿è¡Œæµ‹è¯•
    loader = unittest.TestLoader()

    # åŠ è½½ç‰¹å®šçš„æµ‹è¯•æ¨¡å—
    try:
        suite = loader.loadTestsFromName('tests.test_model_comparison')
    except ImportError as e:
        print(f"âŒ æ— æ³•å¯¼å…¥æµ‹è¯•æ¨¡å—: {e}")
        return 1

    # è¿è¡Œæµ‹è¯•
    runner = unittest.TextTestRunner(
        verbosity=2,
        stream=sys.stdout,
        buffer=False
    )

    result = runner.run(suite)

    # è¾“å‡ºæµ‹è¯•ç»“æœæ‘˜è¦
    print("\n" + "="*80)
    print("ğŸ æµ‹è¯•å®Œæˆï¼")
    print(f"è¿è¡Œæµ‹è¯•: {result.testsRun}")
    print(f"å¤±è´¥: {len(result.failures)}")
    print(f"é”™è¯¯: {len(result.errors)}")
    print(f"è·³è¿‡: {len(result.skipped)}")

    if result.failures:
        print("\nâŒ å¤±è´¥çš„æµ‹è¯•:")
        for test, traceback in result.failures:
            print(f"  - {test}: {traceback.split(chr(10))[-2] if chr(10) in traceback else traceback}")

    if result.errors:
        print("\nğŸ’¥ é”™è¯¯çš„æµ‹è¯•:")
        for test, traceback in result.errors:
            print(f"  - {test}: {traceback.split(chr(10))[-2] if chr(10) in traceback else traceback}")

    if result.skipped:
        print(f"\nâ­ï¸ è·³è¿‡çš„æµ‹è¯•: {len(result.skipped)}")
        for test, reason in result.skipped:
            print(f"  - {test}: {reason}")

    print("="*80)

    # è¿”å›é€€å‡ºä»£ç 
    return 0 if result.wasSuccessful() else 1

def run_specific_test(test_name=None):
    """è¿è¡Œç‰¹å®šæµ‹è¯•"""
    if test_name:
        print(f"ğŸ¯ è¿è¡Œç‰¹å®šæµ‹è¯•: {test_name}")
        loader = unittest.TestLoader()
        suite = loader.loadTestsFromName(f'tests.test_model_comparison.{test_name}')
    else:
        print("ğŸ§ª è¿è¡Œæ‰€æœ‰æ¨¡å‹æ¯”è¾ƒæµ‹è¯•...")
        suite = unittest.TestLoader().discover('tests', pattern='test_*.py')

    runner = unittest.TextTestRunner(verbosity=2)
    result = runner.run(suite)

    return 0 if result.wasSuccessful() else 1

if __name__ == '__main__':
    import argparse

    parser = argparse.ArgumentParser(description='è¿è¡ŒQwen Imageæ¨¡å‹æµ‹è¯•')
    parser.add_argument('--test', '-t', help='è¿è¡Œç‰¹å®šæµ‹è¯•æ–¹æ³•', default=None)
    parser.add_argument('--list', '-l', action='store_true', help='åˆ—å‡ºæ‰€æœ‰å¯ç”¨æµ‹è¯•')

    args = parser.parse_args()

    if args.list:
        print("ğŸ“ å¯ç”¨çš„æµ‹è¯•:")
        print("  TestModelComparison:")
        print("    - test_local_model_creation")
        print("    - test_pretrained_model_loading")
        print("    - test_parameter_count_comparison")
        print("    - test_parameter_shapes_comparison")
        print("    - test_parameter_names_completeness")
        print("    - test_config_comparison")
        print("  TestModelFunctionality:")
        print("    - test_model_forward_pass")
        print("\nä½¿ç”¨æ–¹æ³•: python run_tests.py --test TestModelComparison.test_parameter_shapes_comparison")
        sys.exit(0)

    if args.test:
        exit_code = run_specific_test(args.test)
    else:
        exit_code = run_model_comparison_tests()

    sys.exit(exit_code)
