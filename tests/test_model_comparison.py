#!/usr/bin/env python3
"""
ä½¿ç”¨unittestæµ‹è¯•æ¡†æ¶æ¯”è¾ƒQwen Imageæ¨¡å‹å‚æ•°å½¢çŠ¶å’Œåç§°
"""

import unittest
import torch
import sys
import os
from typing import Dict, Tuple, List
from tabulate import tabulate

# æ·»åŠ é¡¹ç›®æ ¹ç›®å½•åˆ°Pythonè·¯å¾„
sys.path.insert(0, os.path.join(os.path.dirname(__file__), '..'))

from src.models.transformer_qwenimage import QwenImageTransformer2DModel


class TestModelComparison(unittest.TestCase):
    """æµ‹è¯•æ¨¡å‹æ¯”è¾ƒåŠŸèƒ½"""

    @classmethod
    def setUpClass(cls):
        """åˆå§‹åŒ–æµ‹è¯•ç±»ï¼Œåˆ›å»ºéœ€è¦æ¯”è¾ƒçš„æ¨¡å‹"""
        cls.local_model = None
        cls.pretrained_model = None
        cls.load_models()

    @classmethod
    def load_models(cls):
        """åŠ è½½æœ¬åœ°æ¨¡å‹å’Œé¢„è®­ç»ƒæ¨¡å‹"""
        try:
            # åˆ›å»ºæœ¬åœ°æ¨¡å‹
            print("\nğŸ“¦ åˆ›å»ºæœ¬åœ°æ¨¡å‹...")
            cls.local_model = QwenImageTransformer2DModel(
                patch_size=2,
                in_channels=64,
                out_channels=16,
                num_layers=60,
                attention_head_dim=128,
                num_attention_heads=24,
            )
            print("âœ“ æœ¬åœ°æ¨¡å‹åˆ›å»ºæˆåŠŸ")

            # å°è¯•åŠ è½½é¢„è®­ç»ƒæ¨¡å‹
            print("\nğŸ“¥ åŠ è½½é¢„è®­ç»ƒæ¨¡å‹...")
            cls.pretrained_model = QwenImageTransformer2DModel.from_pretrained(
                'Qwen/Qwen-Image-Edit',
                subfolder="transformer",
                torch_dtype=torch.bfloat16
            )
            print("âœ“ é¢„è®­ç»ƒæ¨¡å‹åŠ è½½æˆåŠŸ")

        except Exception as e:
            print(f"âš ï¸ é¢„è®­ç»ƒæ¨¡å‹åŠ è½½å¤±è´¥: {e}")
            cls.pretrained_model = None

    def test_local_model_creation(self):
        """æµ‹è¯•æœ¬åœ°æ¨¡å‹æ˜¯å¦æˆåŠŸåˆ›å»º"""
        self.assertIsNotNone(self.local_model, "æœ¬åœ°æ¨¡å‹åº”è¯¥æˆåŠŸåˆ›å»º")
        self.assertIsInstance(self.local_model, QwenImageTransformer2DModel)

    def test_pretrained_model_loading(self):
        """æµ‹è¯•é¢„è®­ç»ƒæ¨¡å‹æ˜¯å¦æˆåŠŸåŠ è½½"""
        if self.pretrained_model is None:
            self.skipTest("é¢„è®­ç»ƒæ¨¡å‹æ— æ³•åŠ è½½ï¼Œè·³è¿‡æµ‹è¯•")

        self.assertIsNotNone(self.pretrained_model, "é¢„è®­ç»ƒæ¨¡å‹åº”è¯¥æˆåŠŸåŠ è½½")
        self.assertIsInstance(self.pretrained_model, QwenImageTransformer2DModel)

    def test_parameter_count_comparison(self):
        """æµ‹è¯•å‚æ•°æ•°é‡æ¯”è¾ƒ"""
        if self.pretrained_model is None:
            self.skipTest("é¢„è®­ç»ƒæ¨¡å‹æ— æ³•åŠ è½½ï¼Œè·³è¿‡æµ‹è¯•")

        # è®¡ç®—å‚æ•°æ•°é‡
        local_params = sum(p.numel() for p in self.local_model.parameters())
        pretrained_params = sum(p.numel() for p in self.pretrained_model.parameters())

        print(f"\nğŸ“Š å‚æ•°æ•°é‡æ¯”è¾ƒ:")
        print(f"  æœ¬åœ°æ¨¡å‹: {local_params:,} å‚æ•°")
        print(f"  é¢„è®­ç»ƒæ¨¡å‹: {pretrained_params:,} å‚æ•°")
        print(f"  å·®å¼‚: {abs(local_params - pretrained_params):,} å‚æ•°")

        # éªŒè¯å‚æ•°æ•°é‡ä¸ºæ­£æ•°
        self.assertGreater(local_params, 0, "æœ¬åœ°æ¨¡å‹å‚æ•°æ•°é‡åº”å¤§äº0")
        self.assertGreater(pretrained_params, 0, "é¢„è®­ç»ƒæ¨¡å‹å‚æ•°æ•°é‡åº”å¤§äº0")

    def test_parameter_shapes_comparison(self):
        """æµ‹è¯•å‚æ•°å½¢çŠ¶æ¯”è¾ƒ"""
        if self.pretrained_model is None:
            self.skipTest("é¢„è®­ç»ƒæ¨¡å‹æ— æ³•åŠ è½½ï¼Œè·³è¿‡æµ‹è¯•")

        local_params = dict(self.local_model.named_parameters())
        pretrained_params = dict(self.pretrained_model.named_parameters())

        # è·å–æ¯”è¾ƒç»“æœ
        comparison_results = self._compare_parameter_shapes(local_params, pretrained_params)

        # ç”ŸæˆæŠ¥å‘Š
        self._print_parameter_comparison_report(comparison_results)

        # æ–­è¨€è‡³å°‘æœ‰ä¸€äº›åŒ¹é…çš„å‚æ•°
        matching_count = len([r for r in comparison_results['detailed'] if r['status'] == 'match'])
        self.assertGreater(matching_count, 0, "åº”è¯¥è‡³å°‘æœ‰ä¸€äº›å‚æ•°å½¢çŠ¶åŒ¹é…")

    def test_parameter_names_completeness(self):
        """æµ‹è¯•å‚æ•°åç§°å®Œæ•´æ€§"""
        if self.pretrained_model is None:
            self.skipTest("é¢„è®­ç»ƒæ¨¡å‹æ— æ³•åŠ è½½ï¼Œè·³è¿‡æµ‹è¯•")

        local_param_names = set(name for name, _ in self.local_model.named_parameters())
        pretrained_param_names = set(name for name, _ in self.pretrained_model.named_parameters())

        missing_in_local = pretrained_param_names - local_param_names
        missing_in_pretrained = local_param_names - pretrained_param_names

        if missing_in_local:
            print(f"\nâŒ æœ¬åœ°æ¨¡å‹ç¼ºå¤±çš„å‚æ•°: {len(missing_in_local)}")
            for name in sorted(missing_in_local):
                print(f"  - {name}")

        if missing_in_pretrained:
            print(f"\nâŒ é¢„è®­ç»ƒæ¨¡å‹ç¼ºå¤±çš„å‚æ•°: {len(missing_in_pretrained)}")
            for name in sorted(missing_in_pretrained):
                print(f"  - {name}")

        # è®°å½•å·®å¼‚ä½†ä¸å¤±è´¥æµ‹è¯•ï¼ˆå› ä¸ºè¿™å¯èƒ½æ˜¯é¢„æœŸçš„ï¼‰
        self.assertIsInstance(missing_in_local, set)
        self.assertIsInstance(missing_in_pretrained, set)

    def test_config_comparison(self):
        """æµ‹è¯•æ¨¡å‹é…ç½®æ¯”è¾ƒ"""
        if self.pretrained_model is None:
            self.skipTest("é¢„è®­ç»ƒæ¨¡å‹æ— æ³•åŠ è½½ï¼Œè·³è¿‡æµ‹è¯•")

        # æ¯”è¾ƒé…ç½®
        config_results = self._compare_model_configs()
        self._print_config_comparison_report(config_results)

        # éªŒè¯é…ç½®å­˜åœ¨
        self.assertTrue(hasattr(self.local_model, 'config') or hasattr(self.pretrained_model, 'config'),
                       "è‡³å°‘ä¸€ä¸ªæ¨¡å‹åº”è¯¥æœ‰é…ç½®ä¿¡æ¯")

    def _compare_parameter_shapes(self, params1: Dict, params2: Dict) -> Dict:
        """æ¯”è¾ƒä¸¤ä¸ªå‚æ•°å­—å…¸çš„å½¢çŠ¶"""
        all_param_names = set(params1.keys()) | set(params2.keys())

        detailed_results = []
        shape_mismatches = []
        missing_in_model1 = []
        missing_in_model2 = []

        for param_name in sorted(all_param_names):
            if param_name in params1 and param_name in params2:
                shape1 = tuple(params1[param_name].shape)
                shape2 = tuple(params2[param_name].shape)

                if shape1 == shape2:
                    detailed_results.append({
                        'name': param_name,
                        'shape1': shape1,
                        'shape2': shape2,
                        'status': 'match'
                    })
                else:
                    detailed_results.append({
                        'name': param_name,
                        'shape1': shape1,
                        'shape2': shape2,
                        'status': 'mismatch'
                    })
                    shape_mismatches.append((param_name, shape1, shape2))

            elif param_name in params1:
                shape1 = tuple(params1[param_name].shape)
                detailed_results.append({
                    'name': param_name,
                    'shape1': shape1,
                    'shape2': None,
                    'status': 'missing_in_model2'
                })
                missing_in_model2.append((param_name, shape1))

            else:  # param_name in params2
                shape2 = tuple(params2[param_name].shape)
                detailed_results.append({
                    'name': param_name,
                    'shape1': None,
                    'shape2': shape2,
                    'status': 'missing_in_model1'
                })
                missing_in_model1.append((param_name, shape2))

        return {
            'detailed': detailed_results,
            'shape_mismatches': shape_mismatches,
            'missing_in_model1': missing_in_model1,
            'missing_in_model2': missing_in_model2
        }

    def _compare_model_configs(self) -> Dict:
        """æ¯”è¾ƒæ¨¡å‹é…ç½®"""
        config1 = getattr(self.local_model, 'config', {})
        config2 = getattr(self.pretrained_model, 'config', {})

        if not isinstance(config1, dict):
            config1 = config1.__dict__ if hasattr(config1, '__dict__') else {}
        if not isinstance(config2, dict):
            config2 = config2.__dict__ if hasattr(config2, '__dict__') else {}

        all_keys = set(config1.keys()) | set(config2.keys())

        config_comparison = []
        for key in sorted(all_keys):
            val1 = config1.get(key, "ç¼ºå¤±")
            val2 = config2.get(key, "ç¼ºå¤±")

            status = "åŒ¹é…" if val1 == val2 else "ä¸åŒ"
            config_comparison.append({
                'key': key,
                'value1': str(val1),
                'value2': str(val2),
                'status': status
            })

        return config_comparison

    def _print_parameter_comparison_report(self, results: Dict):
        """æ‰“å°å‚æ•°æ¯”è¾ƒæŠ¥å‘Š"""
        print(f"\n{'='*80}")
        print("ğŸ“‹ å‚æ•°å½¢çŠ¶æ¯”è¾ƒè¯¦ç»†æŠ¥å‘Š")
        print(f"{'='*80}")

        # å‡†å¤‡è¡¨æ ¼æ•°æ®
        table_data = []
        for item in results['detailed']:
            status_symbol = {
                'match': 'âœ“ åŒ¹é…',
                'mismatch': 'âœ— ä¸åŒ¹é…',
                'missing_in_model1': 'âœ— ä»…åœ¨é¢„è®­ç»ƒ',
                'missing_in_model2': 'âœ— ä»…åœ¨æœ¬åœ°'
            }

            shape1_str = str(item['shape1']) if item['shape1'] else "ç¼ºå¤±"
            shape2_str = str(item['shape2']) if item['shape2'] else "ç¼ºå¤±"

            table_data.append([
                item['name'],
                shape1_str,
                shape2_str,
                status_symbol[item['status']]
            ])

        headers = ["å‚æ•°å", "æœ¬åœ°æ¨¡å‹å½¢çŠ¶", "é¢„è®­ç»ƒæ¨¡å‹å½¢çŠ¶", "çŠ¶æ€"]
        print(tabulate(table_data, headers=headers, tablefmt="grid"))

        # æ‰“å°æ‘˜è¦
        total_params = len(results['detailed'])
        matching_params = len([r for r in results['detailed'] if r['status'] == 'match'])

        print(f"\nğŸ“ˆ æ¯”è¾ƒæ‘˜è¦:")
        print(f"  æ€»å‚æ•°æ•°é‡: {total_params}")
        print(f"  åŒ¹é…å‚æ•°: {matching_params}")
        print(f"  å½¢çŠ¶ä¸åŒ¹é…: {len(results['shape_mismatches'])}")
        print(f"  ä»…åœ¨æœ¬åœ°æ¨¡å‹: {len(results['missing_in_model2'])}")
        print(f"  ä»…åœ¨é¢„è®­ç»ƒæ¨¡å‹: {len(results['missing_in_model1'])}")

    def _print_config_comparison_report(self, config_results: List[Dict]):
        """æ‰“å°é…ç½®æ¯”è¾ƒæŠ¥å‘Š"""
        print(f"\nâš™ï¸ æ¨¡å‹é…ç½®æ¯”è¾ƒ:")

        if not config_results:
            print("  é…ç½®ä¿¡æ¯ä¸å®Œæ•´æˆ–æ ¼å¼ä¸æ”¯æŒ")
            return

        table_data = [[item['key'], item['value1'], item['value2'], item['status']]
                     for item in config_results]

        headers = ["é…ç½®é¡¹", "æœ¬åœ°æ¨¡å‹", "é¢„è®­ç»ƒæ¨¡å‹", "çŠ¶æ€"]
        print(tabulate(table_data, headers=headers, tablefmt="grid"))


class TestModelFunctionality(unittest.TestCase):
    """æµ‹è¯•æ¨¡å‹åŸºæœ¬åŠŸèƒ½"""

    def setUp(self):
        """æ¯ä¸ªæµ‹è¯•å‰çš„è®¾ç½®"""
        self.model = QwenImageTransformer2DModel(
            patch_size=2,
            in_channels=64,
            out_channels=16,
            num_layers=60,
            attention_head_dim=128,
            num_attention_heads=24,
        )

    def test_model_forward_pass(self):
        """æµ‹è¯•æ¨¡å‹å‰å‘ä¼ æ’­"""
        # åˆ›å»ºæµ‹è¯•è¾“å…¥
        batch_size = 2
        height, width = 64, 64
        in_channels = 64
        seq_len = 128  # æ–‡æœ¬åºåˆ—é•¿åº¦

        # ä»æ¨¡å‹é…ç½®ä¸­è·å–æ­£ç¡®çš„ç»´åº¦
        joint_attention_dim = getattr(self.model.config, 'joint_attention_dim', 3584)
        print(f"ä½¿ç”¨ joint_attention_dim: {joint_attention_dim}")

        hidden_states = torch.randn(batch_size, in_channels, height, width)
        timestep = torch.randint(0, 1000, (batch_size,))

        # Qwenæ¨¡å‹è¿˜éœ€è¦æ–‡æœ¬ç¼–ç å™¨çš„è¾“å‡ºï¼Œä½¿ç”¨æ­£ç¡®çš„ç»´åº¦
        encoder_hidden_states = torch.randn(batch_size, seq_len, joint_attention_dim)

        # å¯é€‰å‚æ•°
        txt_seq_lens = [seq_len] * batch_size
        img_shapes = [(1, height, width)] * batch_size

        # æµ‹è¯•å‰å‘ä¼ æ’­
        with torch.no_grad():
            try:
                output = self.model(
                    hidden_states=hidden_states,
                    encoder_hidden_states=encoder_hidden_states,
                    timestep=timestep,
                    txt_seq_lens=txt_seq_lens,
                    img_shapes=img_shapes
                )

                # éªŒè¯è¾“å‡ºå½¢çŠ¶
                self.assertIsNotNone(output, "æ¨¡å‹è¾“å‡ºä¸åº”è¯¥ä¸ºNone")
                if hasattr(output, 'sample'):
                    output_tensor = output.sample
                else:
                    output_tensor = output

                expected_shape = (batch_size, 16, height, width)  # out_channels=16
                self.assertEqual(tuple(output_tensor.shape), expected_shape,
                                f"è¾“å‡ºå½¢çŠ¶åº”è¯¥æ˜¯{expected_shape}")

                print(f"âœ… å‰å‘ä¼ æ’­æµ‹è¯•æˆåŠŸï¼è¾“å‡ºå½¢çŠ¶: {output_tensor.shape}")

            except Exception as e:
                print(f"âš ï¸ å‰å‘ä¼ æ’­æµ‹è¯•è·³è¿‡: {e}")
                # å¦‚æœé‡åˆ°å…¶ä»–é…ç½®é—®é¢˜ï¼Œè·³è¿‡è€Œä¸æ˜¯å¤±è´¥
                self.skipTest(f"å‰å‘ä¼ æ’­éœ€è¦æ›´å¤šé…ç½®å‚æ•°: {e}")


if __name__ == '__main__':
    # è®¾ç½®è¯¦ç»†è¾“å‡º
    unittest.main(verbosity=2, buffer=False)
