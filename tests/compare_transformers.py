#!/usr/bin/env python3
"""
æ¯”è¾ƒä¸¤ç§transformeråŠ è½½æ–¹å¼æ˜¯å¦å¾—åˆ°ç›¸åŒçš„æ¨¡å‹
"""

import torch
import sys
import os
sys.path.append(os.path.dirname(os.path.abspath(__file__)))

from src.models.load_model import load_transformer
from diffusers.pipelines.qwenimage.pipeline_qwenimage_edit import QwenImageEditPipeline


def compare_models(model1, model2, model_name="models"):
    """æ¯”è¾ƒä¸¤ä¸ªæ¨¡å‹æ˜¯å¦ç›¸åŒ"""
    print(f"ğŸ” æ¯”è¾ƒ {model_name}...")

    # 1. æ£€æŸ¥æ¨¡å‹ç±»å‹
    print(f"Model 1 ç±»å‹: {type(model1)}")
    print(f"Model 2 ç±»å‹: {type(model2)}")

    if type(model1) != type(model2):
        print("âŒ æ¨¡å‹ç±»å‹ä¸åŒï¼")
    else:
        print("âœ… æ¨¡å‹ç±»å‹ç›¸åŒ")

    # 2. æ£€æŸ¥æ¨¡å‹ç»“æ„
    print(f"\nModel 1 å‚æ•°æ•°é‡: {sum(p.numel() for p in model1.parameters()):,}")
    print(f"Model 2 å‚æ•°æ•°é‡: {sum(p.numel() for p in model2.parameters()):,}")

    # 3. æ£€æŸ¥state_dicté”®
    state_dict1 = model1.state_dict()
    state_dict2 = model2.state_dict()

    keys1 = set(state_dict1.keys())
    keys2 = set(state_dict2.keys())

    print(f"\nModel 1 å‚æ•°é”®æ•°é‡: {len(keys1)}")
    print(f"Model 2 å‚æ•°é”®æ•°é‡: {len(keys2)}")

    if keys1 != keys2:
        print("âŒ å‚æ•°é”®ä¸å®Œå…¨ç›¸åŒï¼")
        print(f"Model 1 ç‹¬æœ‰çš„é”®: {keys1 - keys2}")
        print(f"Model 2 ç‹¬æœ‰çš„é”®: {keys2 - keys1}")
    else:
        print("âœ… å‚æ•°é”®å®Œå…¨ç›¸åŒ")

    # 4. æ£€æŸ¥å‚æ•°å€¼æ˜¯å¦ç›¸åŒ
    print("\nğŸ” æ£€æŸ¥å‚æ•°å€¼...")
    differences = 0
    max_diff = 0.0

    for key in keys1:
        param1 = state_dict1[key]
        param2 = state_dict2[key]

        if param1.shape != param2.shape:
            print(f"âŒ å‚æ•° {key} çš„å½¢çŠ¶ä¸åŒ: {param1.shape} vs {param2.shape}")
            differences += 1

        diff = torch.abs(param1 - param2).max().item()
        max_diff = max(max_diff, diff)

        if diff > 1e-6:  # è®¾ç½®ä¸€ä¸ªå°çš„é˜ˆå€¼
            print(f"âš ï¸  å‚æ•° {key} æœ‰å·®å¼‚: æœ€å¤§å·®å€¼ = {diff}")
            differences += 1

    print(f"\nğŸ“Š æ¯”è¾ƒç»“æœ:")
    print(f"å‚æ•°å·®å¼‚æ•°é‡: {differences}")
    print(f"æœ€å¤§å·®å€¼: {max_diff}")

    if differences == 0:
        print("âœ… æ‰€æœ‰å‚æ•°å€¼å®Œå…¨ç›¸åŒï¼")
        return True
    else:
        print(f"âŒ å‘ç° {differences} ä¸ªå‚æ•°æœ‰å·®å¼‚")
        return False


def main():
    """ä¸»å‡½æ•°"""
    print("ğŸš€ å¼€å§‹æ¯”è¾ƒä¸¤ç§transformeråŠ è½½æ–¹å¼...")

    model_path = "Qwen/Qwen-Image-Edit"
    weight_dtype = torch.bfloat16

    # æ–¹æ³•1ï¼šä»QwenImageEditPipelineåŠ è½½
    print(f"\nğŸ“¥ æ–¹æ³•1: ä»QwenImageEditPipelineåŠ è½½...")
    pipe = QwenImageEditPipeline.from_pretrained(
        model_path,
        torch_dtype=weight_dtype
    )
    transformer1 = pipe.transformer
    print("âœ… æ–¹æ³•1åŠ è½½æˆåŠŸ")

    # æ–¹æ³•2ï¼šç›´æ¥åŠ è½½transformer
    print(f"\nğŸ“¥ æ–¹æ³•2: ç›´æ¥åŠ è½½transformer...")
    transformer2 = load_transformer(model_path, weight_dtype)
    print("âœ… æ–¹æ³•2åŠ è½½æˆåŠŸ")

    # æ¯”è¾ƒä¸¤ä¸ªæ¨¡å‹
    print(f"\n" + "="*50)
    is_same = compare_models(transformer1, transformer2, "transformers")
    print("="*50)

    if is_same:
        print("ğŸ‰ ç»“è®º: ä¸¤ç§åŠ è½½æ–¹å¼å¾—åˆ°çš„transformeræ¨¡å‹å®Œå…¨ç›¸åŒï¼")
    else:
        print("âš ï¸  ç»“è®º: ä¸¤ç§åŠ è½½æ–¹å¼å¾—åˆ°çš„transformeræ¨¡å‹ä¸å®Œå…¨ç›¸åŒ")

    # é¢å¤–ä¿¡æ¯
    print(f"\nğŸ“‹ é¢å¤–ä¿¡æ¯:")
    print(f"Pipeline transformer device: {transformer1.device}")
    print(f"Direct load transformer device: {transformer2.device}")
    print(f"Pipeline transformer dtype: {next(transformer1.parameters()).dtype}")
    print(f"Direct load transformer dtype: {next(transformer2.parameters()).dtype}")

    # æ£€æŸ¥é…ç½®
    if hasattr(transformer1, 'config') and hasattr(transformer2, 'config'):
        config1 = transformer1.config
        config2 = transformer2.config
        print(f"\nâš™ï¸  é…ç½®æ¯”è¾ƒ:")
        print(f"Config 1: {config1}")
        print(f"Config 2: {config2}")
        print(f"é…ç½®ç›¸åŒ: {config1 == config2}")

if __name__ == "__main__":
    main()
