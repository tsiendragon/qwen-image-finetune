model:
  pretrained_model_name_or_path: "Qwen/Qwen-Image-Edit"
  rank: 16
  quantize: true
  lora:
    r: 16
    lora_alpha: 16
    init_lora_weights: "gaussian"
    target_modules: ["to_k", "to_q", "to_v", "to_out.0"]
    pretrained_weight: null

data:
  class_path: "src.data.dataset.ImageDataset"
  init_args:
    dataset_path: "/data/kyc_gen/id_card/"
    image_size: [832, 576]
    caption_dropout_rate: 0.1
    prompt_image_dropout_rate: 0.1

    cache_dir: ${cache.cache_dir}
    use_cache: ${cache.use_cache}


  batch_size: 2
  num_workers: 2
  shuffle: true

logging:
  output_dir: "/data/lilong/experiment/id_card_qwen_image_lora"
  logging_dir: "logs"
  report_to: "tensorboard"
  tracker_project_name: "lora_test"

optimizer:
  class_path: bnb.optim.Adam8bit
  init_args:
    lr: 0.0002
    betas: [0.9, 0.999]
  # class_path: "torch.optim.AdamW"
  # init_args:
  #   lr: 0.0002
  #   weight_decay: 0.01
  #   betas: [0.9, 0.999]
  #   eps: 1e-8

lr_scheduler:
  scheduler_type: "constant_with_warmup"
  warmup_steps: 10
  num_cycles: 0.5
  power: 1.0

train:
  gradient_accumulation_steps: 1
  max_train_steps: 3000
  num_epochs: 3
  checkpointing_steps: 250
  checkpoints_total_limit: 10
  max_grad_norm: 1.0
  mixed_precision: "bf16"


cache:
  vae_encoder_device: cuda:1
  text_encoder_device: cuda:2
  cache_dir: "/data/lilong/experiment/id_card_qwen_image_lora/cache"
  use_cache: true


predict:
  devices:
    vae: cuda:5
    text_encoder: cuda:6
    transformer: cuda:7
# Additional training parameters that may be needed
resume_from_checkpoint: "latest"
